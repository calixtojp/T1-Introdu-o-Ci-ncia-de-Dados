# ClassificaÃ§Ã£o de Fumantes a partir de Bio-sinais

![Python](https://img.shields.io/badge/python-3.8%2B-blue) ![scikit-learn](https://img.shields.io/badge/scikit--learn-1.1-green) ![MIT License](https://img.shields.io/badge/license-MIT-lightgrey)

## SumÃ¡rio

- [Contexto e Problema](#contexto-e-problema)  
- [DescriÃ§Ã£o do Dataset](#descriÃ§Ã£o-do-dataset)  
- [Metodologia](#metodologia)  
  - [PrÃ©-processamento](#prÃ©-processamento)  
  - [Modelagem](#modelagem)  
  - [ValidaÃ§Ã£o e MÃ©tricas](#validaÃ§Ã£o-e-mÃ©tricas)  
- [Resultados Principais](#resultados-principais)  
- [Estrutura do Projeto](#estrutura-do-projeto)  
- [Como Executar](#como-executar)  
- [Boas PrÃ¡ticas Adotadas](#boas-prÃ¡ticas-adotadas)  
- [LicenÃ§a](#licenÃ§a)  

---

## Contexto e Problema

Determinamos se um indivÃ­duo Ã© fumante ou nÃ£o a partir de **bio-sinais** bÃ¡sicos de saÃºde (pressÃ£o arterial, colesterol, exames de visÃ£o, Ã­ndice de massa corporal etc.).  
O desafio envolve:

1. **ClassificaÃ§Ã£o binÃ¡ria** (fumante vs. nÃ£o-fumante).  
2. Alto volume de registros (55 692 linhas, 27 colunas).  
3. Desejo de identificar quais sinais tÃªm maior poder preditivo.

---

## DescriÃ§Ã£o do Dataset

- **Origem**: Kaggle â€“ â€œBasic Health Bio-Signalsâ€  
- **Formato**: CSV (`smoking.csv`, 55 692 registros Ã— 27 atributos)  
- **Particionamento**:  
  - Treino (`df_train`): 44 553 registros  
  - Teste (`df_test`): 11 139 registros  
- **Colunas principais**:  
  - `gender`, `age` (intervalos de 5 anos), `height`, `weight`, `waist`  
  - Sinais vitais: `systolic`, `relaxation`, `fasting_blood_sugar`, `cholesterol`, `triglyceride`, `HDL`, `LDL`  
  - Enzimas hepÃ¡ticas: `AST`, `ALT`, `Gtp`  
  - Exames: `eyesight_left`, `eyesight_right`, `hearing_left`, `hearing_right`, `oral`, `dental_caries`, `tartar`  
  - **Target**: `smoking` (0 = nÃ£o, 1 = sim)  

Alguns passos de **pÃ³s-processamento** e **filtragem** foram aplicados (remoÃ§Ã£o de outliers, preenchimento de dados faltantes).

---

## Metodologia

### PrÃ©-processamento

1. **Tratamento de valores ausentes**  
   - Preenchimento com mediana (variÃ¡veis contÃ­nuas) ou moda (categÃ³ricas).
2. **CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas**  
   - `OneHotEncoder` para colunas de baixa cardinalidade.  
   - `OrdinalEncoder` em exames com ordem natural (â€œnenhumâ€, â€œleveâ€, â€œgraveâ€).
3. **Escalonamento**  
   - `StandardScaler` para normalizar distribuiÃ§Ãµes e facilitar convergÃªncia de algoritmos.
4. **SeleÃ§Ã£o de caracterÃ­sticas**  
   - **Filtro univariado** (Teste qui-quadrado / ANOVA) para reduzir dimensionalidade.  
   - Experimentamos conjuntos de tamanhos entre 70 e 80 atributos selecionados via cross-validation.

### Modelagem

Testamos 10 algoritmos clÃ¡ssicos, todos dentro de pipelines para garantir reprodutibilidade:

| Modelo                              | Biblioteca           |
| ----------------------------------- | -------------------- |
| GaussianNB & BernoulliNB            | `sklearn.naive_bayes`|
| k-Nearest Neighbors (KNN)           | `sklearn.neighbors`  |
| Random Forest                       | `sklearn.ensemble`   |
| Extra Trees                         | `sklearn.ensemble`   |
| Gradient Boosting / HistGB          | `sklearn.ensemble`   |
| XGBoost                              | `xgboost`            |
| LightGBM (GBDT & DART)               | `lightgbm`           |
| CatBoost                             | `catboost`           |

- **Cross-validation estratificada** (10 folds, shuffle + seed fixo).  
- **Tuning** do nÃºmero de features via variaÃ§Ã£o entre 70â€“80.  
- MÃ©tricas calculadas em cada fold: **ROC AUC** e **Accuracy**.

### ValidaÃ§Ã£o e MÃ©tricas

- **ROC AUC**: Ãrea sob curva ROC â€” principal mÃ©trica para classes desbalanceadas.  
- **Accuracy**: Percentual de acerto.  
- **Tempo de treinamento**: monitorado para cada experimento (`time.time()`).

---

## Resultados Principais

- **Melhor configuraÃ§Ã£o**:  
  - **Modelo**: `CatBoostClassifier`  
  - **NÂº de features**: 77  
- **Desempenho mÃ©dio (10-fold CV)**:  
  - **ROC AUC**: 0.83  
  - **Accuracy**: 0.75  
- **Tempo mÃ©dio de treino**: ~9 min

> **Insight**: variÃ¡veis relacionadas a exames hepÃ¡ticos e pressÃ£o arterial foram as que mais contribuÃ­ram (importÃ¢ncia > 0.05 em `feature_importances_`).

---

## Estrutura do Projeto
```
ğŸ“ projeto-smoke-classification/
â”‚
â”œâ”€ data/
â”‚   â”œâ”€ smoking.csv
â”‚   â”œâ”€ processed/
â”‚
â”œâ”€ notebooks/
â”‚   â””â”€ Trabalho\_ICD.ipynb
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ data\_preprocessing.py
â”‚   â”œâ”€ feature\_selection.py
â”‚   â”œâ”€ model\_training.py
â”‚   â””â”€ evaluation.py
â”‚
â”œâ”€ requirements.txt
â”œâ”€ README.md
â””â”€ LICENSE
```

## Como Executar

1. **Clonar o repositÃ³rio**  
   ```bash
   git clone https://github.com/seu-usuario/projeto-smoke-classification.git
   cd projeto-smoke-classification
    ````

2. **Criar ambiente e instalar dependÃªncias**

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```
3. **PrÃ©-processar dados**

   ```bash
   python src/data_preprocessing.py --input data/smoking.csv \
       --output data/processed/train.csv data/processed/test.csv
   ```
4. **Treinar e avaliar**

   ```bash
   python src/model_training.py --config configs/experiment.yml
   python src/evaluation.py --predictions results/preds.csv
   ```

---

## Boas PrÃ¡ticas Adotadas

* **Reprodutibilidade**

  * Uso de `random_state` fixo em todas as rotinas.
  * Pipelines de prÃ©-processamento e modelagem no scikit-learn.
* **OrganizaÃ§Ã£o de CÃ³digo**

  * SeparaÃ§Ã£o clara entre ETL, seleÃ§Ã£o de features, treinamento e avaliaÃ§Ã£o.
  * Scripts parametrizÃ¡veis via linha de comando (`argparse`).
* **Controle de VersÃ£o**

  * `.gitignore` configurado para ignorar dados brutos e ambientes virtuais.
* **DocumentaÃ§Ã£o**

  * ComentÃ¡rios e docstrings em todos os mÃ³dulos.
  * Este `README.md` contÃ©m instruÃ§Ãµes de uso e visÃ£o geral.
* **Teste de Qualidade**

  * Linters: `flake8`, `black`.
  * ValidaÃ§Ã£o de esquemas (pandas-schema) para checar integridade dos dados.

---

## LicenÃ§a

Este projeto estÃ¡ licenciado sob a [MIT License](LICENSE).

```
```
